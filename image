import streamlit as st
import torch
from PIL import Image
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize
from openai import clip

# Load the model
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load('ViT-B/32', device=device)

# Define the preprocessing steps
preprocess = Compose([
    Resize(256, interpolation=Image.BICUBIC),
    CenterCrop(224),
    ToTensor()
])

# Streamlit code
st.title('Image Categorizer using OpenAI CLIP')

uploaded_file = st.file_uploader("Choose an image...", type="jpg")

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image.', use_column_width=True)
    st.write("")

    # Preprocess the image
    image = preprocess(image).unsqueeze(0).to(device)

    # Generate a list of labels
    labels = ["crewneck", "hoodie", "pants", "etc"]

    # Encode the labels
    text = clip.tokenize(labels).to(device)

    # Get the model's prediction
    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text)

    # Calculate the similarity between the image and the labels
    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
    values, indices = similarity[0].topk(5)

    # Output the results
    st.write("The image is most likely:")
    for value, index in zip(values, indices):
        st.write(f"{labels[index]}: {value.item():.2f}%")
